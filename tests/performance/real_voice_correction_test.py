"""
ì‹¤ì œ ìŒì„± íŒŒì¼ì„ ì‚¬ìš©í•œ ë°œìŒ êµì • ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
- ì‹¤ì œ ìŒì„± íŒŒì¼ ë¡œë“œ
- ë°œìŒ ë¶„ì„
- Voice Cloning
- êµì •ëœ ìŒì„± ìƒì„±
- ê²°ê³¼ ë¹„êµ
"""

import asyncio
import base64
import json
import time
import sys
import uuid
import os
import subprocess
import wave
import tempfile
from datetime import datetime
from typing import Dict, List, Optional
from pathlib import Path

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ .env ë¡œë“œ
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))

# .env íŒŒì¼ ê²½ë¡œ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •
env_path = os.path.join(project_root, '.env')
load_dotenv(dotenv_path=env_path)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ í™•ì¸
print(f"ğŸ” .env íŒŒì¼ ê²½ë¡œ: {env_path}")
print(f"ğŸ” .env íŒŒì¼ ì¡´ì¬: {os.path.exists(env_path)}")
print(f"ğŸ” SUPABASE_URL ì„¤ì •ë¨: {'âœ…' if os.getenv('SUPABASE_URL') else 'âŒ'}")
print(f"ğŸ” ELEVENLABS_API_KEY ì„¤ì •ë¨: {'âœ…' if os.getenv('ELEVENLABS_API_KEY') else 'âŒ'}")

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
app_dir = os.path.join(project_root, 'app')

sys.path.insert(0, app_dir)
sys.path.insert(0, project_root)

# ì„œë¹„ìŠ¤ ì„í¬íŠ¸
try:
    from services.voice_cloning_service import voice_cloning_service
    from services.pronunciation_analysis_service import pronunciation_service
    from services.speech_recognition_service import stt_service
    from services.text_to_speech_service import tts_service
    print("âœ… ëª¨ë“  ì„œë¹„ìŠ¤ ì„í¬íŠ¸ ì„±ê³µ")
except ImportError as e:
    print(f"âŒ ì„œë¹„ìŠ¤ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    sys.exit(1)

class RealVoiceCorrectionTester:
    """ì‹¤ì œ ìŒì„±ì„ ì‚¬ìš©í•œ ë°œìŒ êµì • í…ŒìŠ¤íŠ¸"""

    def __init__(self):
        self.user_id = str(uuid.uuid4())
        self.test_results = {}
        self.audio_files_dir = "test_audio_files"  # í…ŒìŠ¤íŠ¸ ìŒì„± íŒŒì¼ ë””ë ‰í† ë¦¬

        # í…ŒìŠ¤íŠ¸ ìŒì„± íŒŒì¼ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.audio_files_dir, exist_ok=True)

    def load_audio_file_as_base64(self, file_path: str) -> Optional[str]:
        """ìŒì„± íŒŒì¼ì„ Base64ë¡œ ë¡œë“œ"""
        try:
            if not os.path.exists(file_path):
                print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
                return None

            with open(file_path, 'rb') as f:
                audio_data = f.read()
                audio_base64 = base64.b64encode(audio_data).decode('utf-8')

            print(f"âœ… ìŒì„± íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {file_path}")
            return audio_base64

        except Exception as e:
            print(f"âŒ ìŒì„± íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None

    def save_base64_to_file(self, audio_base64: str, filename: str) -> str:
        """Base64 ìŒì„±ì„ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            audio_data = base64.b64decode(audio_base64)
            file_path = os.path.join(self.audio_files_dir, filename)

            with open(file_path, 'wb') as f:
                f.write(audio_data)

            print(f"âœ… ìŒì„± íŒŒì¼ ì €ì¥: {file_path}")
            return file_path

        except Exception as e:
            print(f"âŒ ìŒì„± íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")
            return ""

    async def test_voice_correction_pipeline(
            self,
            user_voice_file: str,  # ì‚¬ìš©ì ìŒì„± ìƒ˜í”Œ (Voice Cloneìš©)
            test_voice_file: str,  # í…ŒìŠ¤íŠ¸í•  ë°œìŒ ìŒì„±
            target_text: str,      # ëª©í‘œ í…ìŠ¤íŠ¸
            language: str = "en"
    ) -> Dict:
        """ì „ì²´ ìŒì„± êµì • íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""

        print(f"\nğŸ¯ ìŒì„± êµì • íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print(f"ëª©í‘œ í…ìŠ¤íŠ¸: '{target_text}'")
        print(f"ì–¸ì–´: {language}")

        results = {
            "target_text": target_text,
            "language": language,
            "timestamp": datetime.now().isoformat(),
            "steps": {}
        }

        try:
            # Step 1: ì‚¬ìš©ì ìŒì„± ìƒ˜í”Œ ë¡œë“œ (Voice Cloneìš©)
            print(f"\nğŸ“ Step 1: ì‚¬ìš©ì ìŒì„± ìƒ˜í”Œ ë¡œë“œ")
            user_audio_base64 = self.load_audio_file_as_base64(user_voice_file)
            if not user_audio_base64:
                return {"error": "ì‚¬ìš©ì ìŒì„± ìƒ˜í”Œ ë¡œë“œ ì‹¤íŒ¨"}

            results["steps"]["voice_sample_loaded"] = True

            # Step 2: Voice Clone ìƒì„±
            print(f"\nğŸ­ Step 2: Voice Clone ìƒì„±")
            clone_start = time.time()

            clone_result = await voice_cloning_service.create_user_voice_clone(
                user_id=self.user_id,
                voice_sample_base64=user_audio_base64,
                voice_name=f"TestVoice_{self.user_id}"
            )

            clone_time = time.time() - clone_start
            results["steps"]["voice_clone"] = {
                "success": clone_result.get("success", False),
                "voice_id": clone_result.get("voice_id", ""),
                "time_ms": clone_time * 1000,
                "cached": clone_result.get("cached", False)
            }

            if not clone_result.get("success"):
                print(f"âŒ Voice Clone ìƒì„± ì‹¤íŒ¨: {clone_result.get('error')}")
                return results

            print(f"âœ… Voice Clone ìƒì„± ì™„ë£Œ (Voice ID: {clone_result.get('voice_id')})")

            # Step 3: í…ŒìŠ¤íŠ¸ ìŒì„± ë¡œë“œ ë° ë°œìŒ ë¶„ì„
            print(f"\nğŸ” Step 3: ë°œìŒ ë¶„ì„")
            test_audio_base64 = self.load_audio_file_as_base64(test_voice_file)
            if not test_audio_base64:
                return {"error": "í…ŒìŠ¤íŠ¸ ìŒì„± íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨"}

            analysis_start = time.time()

            pronunciation_analysis = await pronunciation_service.analyze_pronunciation_from_base64(
                audio_base64=test_audio_base64,
                target_text=target_text,
                user_level="B1",
                language=language
            )

            analysis_time = time.time() - analysis_start

            results["steps"]["pronunciation_analysis"] = {
                "time_ms": analysis_time * 1000,
                "scores": {
                    "overall": pronunciation_analysis.overall_score,
                    "pitch": pronunciation_analysis.pitch_score,
                    "rhythm": pronunciation_analysis.rhythm_score,
                    "stress": pronunciation_analysis.stress_score,
                    "fluency": pronunciation_analysis.fluency_score
                },
                "feedback": pronunciation_analysis.detailed_feedback,
                "suggestions": pronunciation_analysis.suggestions
            }

            print(f"âœ… ë°œìŒ ë¶„ì„ ì™„ë£Œ - ì „ì²´ ì ìˆ˜: {pronunciation_analysis.overall_score:.1f}")

            # Step 4: ì›ë³¸ ìŒì„±ì„ STTë¡œ ì¸ì‹
            print(f"\nğŸ¤ Step 4: ì›ë³¸ ìŒì„± STT ì¸ì‹")
            stt_start = time.time()

            original_stt = await stt_service.recognize_from_base64(
                audio_base64=test_audio_base64,
                language=f"{language}-{language.upper()}" if language == "ko" else f"{language}-US"
            )

            stt_time = time.time() - stt_start

            results["steps"]["original_stt"] = {
                "recognized_text": original_stt or "ì¸ì‹ ì‹¤íŒ¨",
                "time_ms": stt_time * 1000,
                "success": original_stt is not None
            }

            print(f"âœ… ì›ë³¸ STT ê²°ê³¼: '{original_stt}'")

            # Step 5: êµì •ëœ ìŒì„± ìƒì„± (ì‚¬ìš©ì ëª©ì†Œë¦¬ë¡œ)
            print(f"\nğŸ”§ Step 5: êµì •ëœ ìŒì„± ìƒì„±")
            correction_start = time.time()

            # Voice IDë¥¼ ì§ì ‘ ì‚¬ìš©
            voice_id = clone_result.get("voice_id")

            # ElevenLabs API ì§ì ‘ í˜¸ì¶œ
            import aiohttp

            api_key = os.getenv("ELEVENLABS_API_KEY")
            url = f"https://api.elevenlabs.io/v1/text-to-speech/{voice_id}"

            headers = {
                "Accept": "audio/mpeg",
                "Content-Type": "application/json",
                "xi-api-key": api_key
            }

            data = {
                "text": target_text,
                "model_id": "eleven_multilingual_v2",
                "voice_settings": {
                    "stability": 0.5,
                    "similarity_boost": 0.75
                }
            }

            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=data, headers=headers) as response:
                    if response.status == 200:
                        audio_data = await response.read()
                        corrected_audio_base64 = base64.b64encode(audio_data).decode('utf-8')
                        corrected_result = {
                            "success": True,
                            "corrected_audio_base64": corrected_audio_base64
                        }
                    else:
                        error_text = await response.text()
                        corrected_result = {
                            "success": False,
                            "error": f"API ì˜¤ë¥˜ {response.status}: {error_text}"
                        }

            correction_time = time.time() - correction_start

            results["steps"]["corrected_generation"] = {
                "success": corrected_result.get("success", False),
                "time_ms": correction_time * 1000,
                "corrections_applied": ["voice_cloning"]
            }

            if not corrected_result.get("success"):
                print(f"âŒ êµì •ëœ ìŒì„± ìƒì„± ì‹¤íŒ¨: {corrected_result.get('error')}")
                return results

            print(f"âœ… êµì •ëœ ìŒì„± ìƒì„± ì™„ë£Œ")

            # êµì •ëœ ìŒì„± íŒŒì¼ ì €ì¥
            corrected_audio_base64 = corrected_result.get("corrected_audio_base64")
            if corrected_audio_base64:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                corrected_file = f"corrected_{self.user_id}_{timestamp}.mp3"  # mp3ë¡œ ë³€ê²½
                corrected_path = self.save_base64_to_file(corrected_audio_base64, corrected_file)
                results["corrected_audio_file"] = corrected_path

            # Step 6: êµì •ëœ ìŒì„±ì„ STTë¡œ ì¸ì‹
            print(f"\nğŸ¯ Step 6: êµì •ëœ ìŒì„± STT ê²€ì¦")

            # MP3ë¥¼ WAVë¡œ ë³€í™˜ (STTëŠ” WAVë§Œ ì§€ì›)
            import subprocess

            corrected_wav_path = corrected_path.replace('.mp3', '_converted.wav')

            convert_command = [
                'ffmpeg',
                '-i', corrected_path,
                '-ar', '16000',
                '-ac', '1',
                '-acodec', 'pcm_s16le',
                '-y',
                corrected_wav_path
            ]

            subprocess.run(convert_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

            # ë³€í™˜ëœ WAV íŒŒì¼ì„ Base64ë¡œ ì½ê¸°
            with open(corrected_wav_path, 'rb') as f:
                corrected_wav_data = f.read()
                corrected_wav_base64 = base64.b64encode(corrected_wav_data).decode('utf-8')

            corrected_stt_start = time.time()

            corrected_stt = await stt_service.recognize_from_base64(
                audio_base64=corrected_wav_base64,
                language=f"{language}-{language.upper()}" if language == "ko" else f"{language}-US"
            )

            corrected_stt_time = time.time() - corrected_stt_start

            # Step 7: ê²°ê³¼ ë¹„êµ ë° í‰ê°€
            print(f"\nğŸ“Š Step 7: ê²°ê³¼ ë¶„ì„")

            # WER ê³„ì‚°
            original_wer = self.calculate_word_error_rate(target_text, original_stt or "")
            corrected_wer = self.calculate_word_error_rate(target_text, corrected_stt or "")

            # ê°œì„ ë„ ê³„ì‚°
            improvement = original_wer - corrected_wer
            improvement_percentage = (improvement / max(original_wer, 0.001)) * 100

            results["evaluation"] = {
                "original_wer": original_wer,
                "corrected_wer": corrected_wer,
                "improvement": improvement,
                "improvement_percentage": improvement_percentage,
                "total_processing_time_ms": (time.time() - clone_start) * 1000
            }

            results["success"] = True

            print(f"âœ… ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            print(f"   ì›ë³¸ WER: {original_wer:.3f}")
            print(f"   êµì • WER: {corrected_wer:.3f}")
            print(f"   ê°œì„ ë„: {improvement_percentage:.1f}%")

            return results

        except Exception as e:
            print(f"âŒ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
            results["error"] = str(e)
            return results

    def calculate_word_error_rate(self, reference: str, hypothesis: str) -> float:
        """Word Error Rate (WER) ê³„ì‚°"""
        if not reference or not hypothesis:
            return 1.0

        ref_words = reference.lower().split()
        hyp_words = hypothesis.lower().split()

        # Levenshtein distance ê¸°ë°˜ WER ê³„ì‚°
        d = [[0] * (len(hyp_words) + 1) for _ in range(len(ref_words) + 1)]

        for i in range(len(ref_words) + 1):
            d[i][0] = i
        for j in range(len(hyp_words) + 1):
            d[0][j] = j

        for i in range(1, len(ref_words) + 1):
            for j in range(1, len(hyp_words) + 1):
                if ref_words[i-1] == hyp_words[j-1]:
                    d[i][j] = d[i-1][j-1]
                else:
                    d[i][j] = min(
                        d[i-1][j] + 1,    # deletion
                        d[i][j-1] + 1,    # insertion
                        d[i-1][j-1] + 1   # substitution
                    )

        return d[len(ref_words)][len(hyp_words)] / len(ref_words) if ref_words else 0

    def generate_test_report(self, results: Dict):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n" + "=" * 80)
        print("ğŸ“‹ ì‹¤ì œ ìŒì„± êµì • í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¦¬í¬íŠ¸")
        print("=" * 80)

        if "error" in results:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {results['error']}")
            return

        print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸ ëŒ€ìƒ:")
        print(f"   ëª©í‘œ í…ìŠ¤íŠ¸: '{results['target_text']}'")
        print(f"   ì–¸ì–´: {results['language']}")
        print(f"   í…ŒìŠ¤íŠ¸ ì‹œê°„: {results['timestamp']}")

        print(f"\nğŸ“Š ì²˜ë¦¬ ë‹¨ê³„ë³„ ê²°ê³¼:")

        steps = results.get("steps", {})

        # Voice Clone
        if "voice_clone" in steps:
            vc = steps["voice_clone"]
            status = "âœ…" if vc["success"] else "âŒ"
            cached_info = " (ìºì‹œë¨)" if vc.get("cached") else ""
            print(f"   {status} Voice Clone: {vc['time_ms']:.0f}ms{cached_info}")

        # ë°œìŒ ë¶„ì„
        if "pronunciation_analysis" in steps:
            pa = steps["pronunciation_analysis"]
            print(f"   âœ… ë°œìŒ ë¶„ì„: {pa['time_ms']:.0f}ms")
            print(f"      ì „ì²´: {pa['scores']['overall']:.1f}, í”¼ì¹˜: {pa['scores']['pitch']:.1f}")
            print(f"      ë¦¬ë“¬: {pa['scores']['rhythm']:.1f}, ê°•ì„¸: {pa['scores']['stress']:.1f}")

        # STT ê²°ê³¼
        if "original_stt" in steps:
            stt = steps["original_stt"]
            status = "âœ…" if stt["success"] else "âŒ"
            print(f"   {status} ì›ë³¸ STT: '{stt['recognized_text']}' ({stt['time_ms']:.0f}ms)")

        # êµì •ëœ ìŒì„± ìƒì„±
        if "corrected_generation" in steps:
            cg = steps["corrected_generation"]
            status = "âœ…" if cg["success"] else "âŒ"
            print(f"   {status} êµì • ìŒì„± ìƒì„±: {cg['time_ms']:.0f}ms")
            if cg.get("corrections_applied"):
                print(f"      ì ìš©ëœ êµì •: {', '.join(cg['corrections_applied'])}")

        # êµì •ëœ STT ê²°ê³¼
        if "corrected_stt" in steps:
            cstt = steps["corrected_stt"]
            status = "âœ…" if cstt["success"] else "âŒ"
            print(f"   {status} êµì • STT: '{cstt['recognized_text']}' ({cstt['time_ms']:.0f}ms)")

        # ì „ì²´ í‰ê°€
        if "evaluation" in results:
            eval_data = results["evaluation"]
            print(f"\nğŸ¯ ì„±ëŠ¥ í‰ê°€:")
            print(f"   ì›ë³¸ WER: {eval_data['original_wer']:.3f}")
            print(f"   êµì • WER: {eval_data['corrected_wer']:.3f}")
            print(f"   ê°œì„ ë„: {eval_data['improvement_percentage']:.1f}%")
            print(f"   ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {eval_data['total_processing_time_ms']:.0f}ms")

            # ì„±ëŠ¥ ë“±ê¸‰
            if eval_data['improvement_percentage'] > 20:
                grade = "ğŸ† ìš°ìˆ˜í•œ ê°œì„ "
            elif eval_data['improvement_percentage'] > 10:
                grade = "ğŸ¥ˆ ì–‘í˜¸í•œ ê°œì„ "
            elif eval_data['improvement_percentage'] > 0:
                grade = "ğŸ¥‰ ì•½ê°„ì˜ ê°œì„ "
            else:
                grade = "âš ï¸ ê°œì„  íš¨ê³¼ ë¯¸ë¯¸"

            print(f"   ê°œì„  ë“±ê¸‰: {grade}")

        # ê²°ê³¼ íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"voice_correction_test_{timestamp}.json"

        try:
            # ê²°ê³¼ë¥¼ ê¹¨ë—í•˜ê²Œ ì •ë¦¬
            clean_results = json.loads(json.dumps(results, ensure_ascii=True))

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(clean_results, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ JSON ì €ì¥ ì˜¤ë¥˜: {e}")
            # ASCIIë¡œ ê°•ì œ ì €ì¥
            with open(filename, 'w', encoding='ascii', errors='ignore') as f:
                json.dump(results, f, ensure_ascii=True, indent=2)

    async def run_interactive_test(self):
        """ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ™ï¸ ì‹¤ì œ ìŒì„±ì„ ì‚¬ìš©í•œ ë°œìŒ êµì • ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
        print("=" * 60)

        # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        print("\nğŸ“ ìŒì„± íŒŒì¼ ê²½ë¡œ ì…ë ¥:")
        user_voice_file = input("ì‚¬ìš©ì ìŒì„± ìƒ˜í”Œ íŒŒì¼ ê²½ë¡œ (Voice Cloneìš©): ").strip()
        test_voice_file = input("í…ŒìŠ¤íŠ¸í•  ë°œìŒ ìŒì„± íŒŒì¼ ê²½ë¡œ: ").strip()
        target_text = input("ëª©í‘œ í…ìŠ¤íŠ¸: ").strip()
        language = input("ì–¸ì–´ (ko/en/ja/zh/fr, ê¸°ë³¸ê°’ en): ").strip() or "en"

        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(user_voice_file):
            print(f"âŒ ì‚¬ìš©ì ìŒì„± íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {user_voice_file}")
            return

        if not os.path.exists(test_voice_file):
            print(f"âŒ í…ŒìŠ¤íŠ¸ ìŒì„± íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_voice_file}")
            return

        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        results = await self.test_voice_correction_pipeline(
            user_voice_file=user_voice_file,
            test_voice_file=test_voice_file,
            target_text=target_text,
            language=language
        )

        # ê²°ê³¼ ì¶œë ¥
        self.generate_test_report(results)

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    tester = RealVoiceCorrectionTester()

    print("ì„ íƒí•˜ì„¸ìš”:")
    print("1. ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸")
    print("2. ì˜ˆì œ í…ŒìŠ¤íŠ¸ (ë¯¸ë¦¬ ì¤€ë¹„ëœ íŒŒì¼ ì‚¬ìš©)")

    choice = input("ì„ íƒ (1 ë˜ëŠ” 2): ").strip()

    if choice == "1":
        await tester.run_interactive_test()
    elif choice == "2":
        # ì˜ˆì œ íŒŒì¼ì´ ìˆë‹¤ë©´ ìë™ í…ŒìŠ¤íŠ¸
        print("â— ì˜ˆì œ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤. test_audio_files ë””ë ‰í† ë¦¬ì— íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        print("ì˜ˆìƒ íŒŒì¼ëª…:")
        print("  - user_voice_sample.wav (ì‚¬ìš©ì ìŒì„± ìƒ˜í”Œ)")
        print("  - test_pronunciation.wav (í…ŒìŠ¤íŠ¸í•  ë°œìŒ)")

        # ì˜ˆì œ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        example_user_file = "test_audio_files/user_voice_sample.wav"
        example_test_file = "test_audio_files/test_pronunciation.wav"

        if os.path.exists(example_user_file) and os.path.exists(example_test_file):
            target_text = input("ëª©í‘œ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            # ì˜ëª»ëœ ë¬¸ì ì œê±°
            target_text = target_text.encode('utf-8', errors='ignore').decode('utf-8', errors='ignore')

            results = await tester.test_voice_correction_pipeline(
                user_voice_file=example_user_file,
                test_voice_file=example_test_file,
                target_text=target_text,
                language="en"
            )
            tester.generate_test_report(results)
        else:
            print("âŒ ì˜ˆì œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")

if __name__ == "__main__":
    asyncio.run(main())
