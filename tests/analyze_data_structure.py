# analyze_data_structure.py - ìˆ˜ì§‘ëœ ë°ì´í„° êµ¬ì¡° ë¶„ì„

import json
import os

def analyze_collected_data():
    """ìˆ˜ì§‘ëœ ë°ì´í„°ì˜ ì‹¤ì œ êµ¬ì¡° ë¶„ì„"""
    
    json_file = 'free_travel_conversations_en_20250722_161841.json'
    
    if not os.path.exists(json_file):
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_file}")
        return
    
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print("ğŸ“Š ë°ì´í„° êµ¬ì¡° ë¶„ì„ ê²°ê³¼:")
        print("=" * 50)
        
        # ì „ì²´ êµ¬ì¡° í™•ì¸
        print(f"âœ… ìµœìƒìœ„ í‚¤ë“¤: {list(data.keys())}")
        
        if 'metadata' in data:
            metadata = data['metadata']
            print(f"ğŸ“‹ ë©”íƒ€ë°ì´í„°:")
            for key, value in metadata.items():
                print(f"   - {key}: {value}")
        
        if 'conversations' in data:
            conversations = data['conversations']
            print(f"\nğŸ’¬ ëŒ€í™” ë°ì´í„°:")
            print(f"   ì´ ëŒ€í™” ìˆ˜: {len(conversations)}")
            
            # ì²« ë²ˆì§¸ ëŒ€í™” êµ¬ì¡° í™•ì¸
            if conversations:
                first_conv = conversations[0]
                print(f"\nğŸ“ ì²« ë²ˆì§¸ ëŒ€í™” ì˜ˆì‹œ:")
                for key, value in first_conv.items():
                    if isinstance(value, str) and len(value) > 100:
                        print(f"   - {key}: {value[:100]}...")
                    else:
                        print(f"   - {key}: {value}")
                
                # ìƒí™©ë³„ ë¶„í¬ í™•ì¸
                situation_count = {}
                dialogue_lengths = []
                
                for conv in conversations:
                    situation = conv.get('situation', 'unknown')
                    situation_count[situation] = situation_count.get(situation, 0) + 1
                    
                    dialogue = conv.get('dialogue', '')
                    dialogue_lengths.append(len(dialogue))
                
                print(f"\nğŸ“Š ìƒí™©ë³„ ë¶„í¬:")
                for situation, count in situation_count.items():
                    print(f"   - {situation}: {count}ê°œ")
                
                avg_length = sum(dialogue_lengths) / len(dialogue_lengths) if dialogue_lengths else 0
                print(f"\nğŸ“ ëŒ€í™” ê¸¸ì´ í†µê³„:")
                print(f"   - í‰ê·  ê¸¸ì´: {avg_length:.1f} ë¬¸ì")
                print(f"   - ìµœì†Œ ê¸¸ì´: {min(dialogue_lengths)} ë¬¸ì")
                print(f"   - ìµœëŒ€ ê¸¸ì´: {max(dialogue_lengths)} ë¬¸ì")
                
                # ìƒ˜í”Œ ëŒ€í™” ë‚´ìš© í™•ì¸
                print(f"\nğŸ” ìƒ˜í”Œ ëŒ€í™” ë‚´ìš©ë“¤:")
                for i, conv in enumerate(conversations[:3]):
                    print(f"\n   ìƒ˜í”Œ {i+1} ({conv.get('situation', 'unknown')}):")
                    dialogue = conv.get('dialogue', '')[:200]
                    print(f"   \"{dialogue}...\"")
                    
                    # ì†ŒìŠ¤ ì •ë³´ í™•ì¸
                    source = conv.get('source', 'unknown')
                    print(f"   ì†ŒìŠ¤: {source}")
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    analyze_collected_data()